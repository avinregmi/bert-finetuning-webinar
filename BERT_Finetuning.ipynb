{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bTU_UPlfRor",
        "colab_type": "text"
      },
      "source": [
        "# BERT Finetuning with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiEyOBHLfk5d",
        "colab_type": "text"
      },
      "source": [
        "## Understanding the Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcTLiMrXC_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozgNVDWgYinS",
        "colab_type": "code",
        "outputId": "d64e9f0e-abd9-4ab5-f1e2-06fcce186c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_b_zYKHZAMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2_BQ3A2gHJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence = 'hehidden likes to play'\n",
        "# # Step 1: Tokenize\n",
        "# tokens = tokenizer.tokenize(sentence)\n",
        "# # Step 2: Add [CLS] and [SEP]\n",
        "# tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "# # Step 3: Pad tokens\n",
        "# padded_tokens = tokens + ['[PAD]' for _ in range(20 - len(tokens))]\n",
        "# attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
        "# # Step 4: Segment ids\n",
        "# seg_ids = [0 for _ in range(len(padded_tokens))] #Optional!\n",
        "# # Step 5: Get BERT vocabulary index for each token\n",
        "# token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwwjM45ygHs1",
        "colab_type": "code",
        "outputId": "57ca459f-9436-4e42-9b88-58d366ad2462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# # Convert to pytorch tensors\n",
        "# token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "# attn_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
        "# seg_ids = torch.tensor(seg_ids).unsqueeze(0)\n",
        "\n",
        "# # Feed them to bert\n",
        "# hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask,\\\n",
        "#                                   token_type_ids = seg_ids)\n",
        "# print(hidden_reps.shape)\n",
        "# print(cls_head.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4uMPQ_Km9_E",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Class and Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDF8EGbJSAmT",
        "colab_type": "code",
        "outputId": "d1538ff6-6c4c-46f8-ce47-88caa98c45f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=bcbac471c8c59874c54f490a237b0e079062c3233adb78e5fee9584e976bd070\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GtmTUYSSCHU",
        "colab_type": "code",
        "outputId": "d4858870-9836-4fe4-b141-4f035517057e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://raw.githubusercontent.com/theneuralbeing/bert-finetuning-webinar/master/data.zip'\n",
        "\n",
        "# Download the file and unzip it (if we haven't already)\n",
        "if not os.path.exists('./data.zip'):\n",
        "    wget.download(url, './data.zip')\n",
        "    !unzip -q data.zip\n",
        "    print('Unzipped Dataset')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwmzHMnzn6ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxKO4u-iTOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        # Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter=',')\n",
        "\n",
        "        # Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Define the Maxlength for padding/truncating\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'review']\n",
        "        label = self.df.loc[index, 'sentiment']\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "\n",
        "        # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        \n",
        "        # Padding/truncating the sentences to the maximum length\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "        \n",
        "        # Convert the sequence to ids with BERT Vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        \n",
        "        # Converting the list to a pytorch tensor\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "\n",
        "        # Obtaining the attention mask\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqe1Tn_gU-mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating instances of training and validation set\n",
        "train_set = LoadDataset(filename = 'data/train.csv', maxlen = 64)\n",
        "val_set = LoadDataset(filename = 'data/validation.csv', maxlen = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBez4GyVISF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy59x1OzMnne",
        "colab_type": "text"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q5zrt4MonMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyKJ_lHWTi_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        # Instantiating the BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        # Defining layers like dropout and linear\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        # Getting contextualized representations from BERT Layer\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        # Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # print('CLS shape: ',cls_rep.shape)\n",
        "\n",
        "        # Feeding cls_rep to the classifier layer\n",
        "        logits = self.classifier(cls_rep)\n",
        "        # print('Logits shape: ',logits.shape)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vifcpKtlU8y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEFyqz_MMvjJ",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOZ_RBDOU68m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "criterion = BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr = 2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrFxN3mLwLMp",
        "colab_type": "code",
        "outputId": "b9688e19-76d2-405c-9a48-990be363c4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gubu6At42C_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a function for calculating accuracy\n",
        "def logits_accuracy(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    preds = (probs > 0.5).long()\n",
        "    acc = (preds.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPYi4_6_2C2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining an evaluation function for training \n",
        "def evaluate(net, criterion, val_loader, device):\n",
        "  \n",
        "    losses, accuracies = 0, 0\n",
        "    \n",
        "    # Setting model to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    count = 0\n",
        "    for (seq, attn_masks, labels) in val_loader:\n",
        "        count += 1\n",
        "\n",
        "        # Move inputs and targets to device\n",
        "        seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "        # Get logit predictions\n",
        "        val_logits = net(seq, attn_masks)\n",
        "\n",
        "        # Calculate loss\n",
        "        val_loss = criterion(val_logits.squeeze(-1), labels.float())\n",
        "        losses += val_loss.item()\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        accuracies += logits_accuracy(val_logits, labels)\n",
        "\n",
        "    return losses / count, accuracies / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OvRi_i4BYqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-95E-ZVVNHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, criterion, optimizer, train_loader, val_loader, device, epochs=4, print_every=100):\n",
        "    \n",
        "    # Move model to device\n",
        "    net.to(device)\n",
        "    # Setting model to training mode\n",
        "    net.train()\n",
        "\n",
        "    print('========== ========== STARTING TRAINING ========== ==========')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print('\\n\\n========== EPOCH {} =========='.format(epoch))        \n",
        "        t1 = time()\n",
        "\n",
        "        for i, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()  \n",
        "\n",
        "            # Moving tensors to device\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            # Obtaining the logits from the model\n",
        "            logits = net(seq,attn_masks)\n",
        "\n",
        "            # Calculating the loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            # Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clipping gradients to tackle exploding gradients\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "\n",
        "            # Optimization step\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % print_every == 0:\n",
        "                print(\"Iteration {} ==== Loss: {}\".format(i+1, loss.item()))\n",
        "\n",
        "        t2 = time()\n",
        "        print('Time Taken for Epoch: {}'.format(t2-t1))\n",
        "        print('\\n========== Validating ==========')\n",
        "        mean_val_loss, mean_val_acc = evaluate(net, criterion, val_loader, device)\n",
        "        print(\"Validation Loss: {}\\nValidation Accuracy: {}\".format(mean_val_loss, mean_val_acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWAQPhpoVd2L",
        "colab_type": "code",
        "outputId": "342a166d-b99b-4fdc-e478-2657776f6ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# starting training\n",
        "train(model, criterion, optimizer, train_loader, val_loader, device, epochs=4, print_every=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== ========== STARTING TRAINING ========== ==========\n",
            "\n",
            "\n",
            "========== EPOCH 0 ==========\n",
            "Iteration 100 ==== Loss: 0.41746145486831665\n",
            "Iteration 200 ==== Loss: 0.7065443992614746\n",
            "Iteration 300 ==== Loss: 0.35546237230300903\n",
            "Iteration 400 ==== Loss: 0.29663240909576416\n",
            "Iteration 500 ==== Loss: 0.32456856966018677\n",
            "Iteration 600 ==== Loss: 0.4115922152996063\n",
            "Iteration 700 ==== Loss: 0.39555254578590393\n",
            "Time Taken for Epoch: 224.4464726448059\n",
            "\n",
            "========== Validating ==========\n",
            "Validation Loss: 0.3636349078048678\n",
            "Validation Accuracy: 0.836756706237793\n",
            "\n",
            "\n",
            "========== EPOCH 1 ==========\n",
            "Iteration 100 ==== Loss: 0.0843903124332428\n",
            "Iteration 200 ==== Loss: 0.5162435173988342\n",
            "Iteration 300 ==== Loss: 0.21195906400680542\n",
            "Iteration 400 ==== Loss: 0.12652884423732758\n",
            "Iteration 500 ==== Loss: 0.1082148626446724\n",
            "Iteration 600 ==== Loss: 0.194356769323349\n",
            "Iteration 700 ==== Loss: 0.19153836369514465\n",
            "Time Taken for Epoch: 221.23945546150208\n",
            "\n",
            "========== Validating ==========\n",
            "Validation Loss: 0.4300841025512694\n",
            "Validation Accuracy: 0.8365169167518616\n",
            "\n",
            "\n",
            "========== EPOCH 2 ==========\n",
            "Iteration 100 ==== Loss: 0.00525244977325201\n",
            "Iteration 200 ==== Loss: 0.16157981753349304\n",
            "Iteration 300 ==== Loss: 0.007013227324932814\n",
            "Iteration 400 ==== Loss: 0.0016148535069078207\n",
            "Iteration 500 ==== Loss: 0.00404581893235445\n",
            "Iteration 600 ==== Loss: 0.004870477132499218\n",
            "Iteration 700 ==== Loss: 0.03303264081478119\n",
            "Time Taken for Epoch: 220.54871702194214\n",
            "\n",
            "========== Validating ==========\n",
            "Validation Loss: 0.738685914982215\n",
            "Validation Accuracy: 0.8276854157447815\n",
            "\n",
            "\n",
            "========== EPOCH 3 ==========\n",
            "Iteration 100 ==== Loss: 0.006632836535573006\n",
            "Iteration 200 ==== Loss: 0.1566249579191208\n",
            "Iteration 300 ==== Loss: 0.0006264324183575809\n",
            "Iteration 400 ==== Loss: 0.058371126651763916\n",
            "Iteration 500 ==== Loss: 0.0014134770026430488\n",
            "Iteration 600 ==== Loss: 0.008360528387129307\n",
            "Iteration 700 ==== Loss: 0.00526720006018877\n",
            "Time Taken for Epoch: 220.3685646057129\n",
            "\n",
            "========== Validating ==========\n",
            "Validation Loss: 0.9072547976708855\n",
            "Validation Accuracy: 0.8349584341049194\n",
            "CPU times: user 13min 23s, sys: 2min 48s, total: 16min 11s\n",
            "Wall time: 23min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GO7grF5FkWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving our model\n",
        "import os\n",
        "\n",
        "save_path = 'checkpoints'\n",
        "\n",
        "if not os.path.isdir(save_path):\n",
        "    os.mkdir(save_path)\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, os.path.join(save_path,'model.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a2mZPKkSYjO",
        "colab_type": "code",
        "outputId": "812b8199-6f0c-4bcb-96be-afa449116725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading the checkpoints for resuming training\n",
        "checkpoint = torch.load('checkpoints/model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZNUfk5MVDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving just the model state for inference\n",
        "torch.save(model.state_dict, 'inference.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIX3h8DATQwD",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FnY36M9pYjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = torch.load('inference.pth')\n",
        "# predictor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfWlpu8Tmgqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sentence, maxlen=64):\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    \n",
        "    # Padding/truncating the sentences to the maximum length\n",
        "    if len(tokens) < maxlen:\n",
        "        tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n",
        "    else:\n",
        "        tokens = tokens[:maxlen-1] + ['[SEP]']\n",
        "    \n",
        "    # Convert the sequence to ids with BERT Vocabulary\n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    # Converting the list to a pytorch tensor\n",
        "    tokens_ids_tensor = torch.tensor(tokens_ids).unsqueeze(0)\n",
        "\n",
        "    # Obtaining the attention mask\n",
        "    attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "    return tokens_ids_tensor, attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCRRcFPfMY1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining an evaluation function for training \n",
        "def predict(net, iseq, masks, device):\n",
        "\n",
        "    # Setting model to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # Move inputs and targets to device\n",
        "    iseq, masks = iseq.to(device), masks.to(device)\n",
        "\n",
        "    # Get logit predictions\n",
        "    p_logit = net(iseq, masks)\n",
        "\n",
        "    probs = torch.sigmoid(p_logit.unsqueeze(-1))\n",
        "    preds = (probs > 0.5).long().squeeze(0)\n",
        "\n",
        "   \n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFuaq52hptQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toks, ams = preprocess('the worst movie ever')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RgOYlnSqwBQ",
        "colab_type": "code",
        "outputId": "9a02fa03-3e7d-4856-b54f-6afb69f606f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(ams.shape)\n",
        "toks.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KetyiqqJqi9q",
        "colab_type": "code",
        "outputId": "27676488-7996-47bc-a139-12e156c920ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(model, toks, ams, 'cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X_mB5yRrnMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}